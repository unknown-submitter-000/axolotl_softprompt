{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/graphllm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "from xopen import xopen\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from softprompt.utility.prompting import (\n",
    "    Item,\n",
    "    get_prompt_tuning_prompt\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_SETTINGS = {\n",
    "    'arxiv':{\n",
    "        'desc': \"Question: Which category from the list that the paper most likely belong to?\",\n",
    "        'categories': ['Artificial Intelligence', 'Computation and Language',\n",
    "                        'Computational Complexity',\n",
    "                        'Computational Engineering, Finance, and Science',\n",
    "                        'Computational Geometry', 'Computer Science and Game Theory',\n",
    "                        'Computer Vision and Pattern Recognition', 'Computers and Society',\n",
    "                        'Cryptography and Security', 'Data Structures and Algorithms',\n",
    "                        'Databases', 'Digital Libraries', 'Discrete Mathematics',\n",
    "                        'Distributed, Parallel, and Cluster Computing',\n",
    "                        'Emerging Technologies', 'Formal Languages and Automata Theory',\n",
    "                        'General Literature', 'Graphics', 'Hardware Architecture',\n",
    "                        'Human-Computer Interaction', 'Information Retrieval',\n",
    "                        'Information Theory', 'Logic in Computer Science',\n",
    "                        'Machine Learning', 'Mathematical Software', 'Multiagent Systems',\n",
    "                        'Multimedia', 'Networking and Internet Architecture',\n",
    "                        'Neural and Evolutionary Computing', 'Numerical Analysis',\n",
    "                        'Operating Systems', 'Other Computer Science', 'Performance',\n",
    "                        'Programming Languages', 'Robotics',\n",
    "                        'Social and Information Networks', 'Software Engineering', 'Sound',\n",
    "                        'Symbolic Computation', 'Systems and Control'],\n",
    "        'question': \"Given the title and abstract of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\"\n",
    "    },\n",
    "    'cora':{\n",
    "        'desc': \"Question: Which category from the list that the paper most likely belong to?\",\n",
    "        'categories': ['Case-Based',\n",
    "                        'Genetic_Algorithms',\n",
    "                        'Neural_Networks',\n",
    "                        'Probabilistic_Methods',\n",
    "                        'Reinforcement_Learning',\n",
    "                        'Rule_Learning',\n",
    "                        'Theory'],\n",
    "        'question': \"Given the title and abstract of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\"\n",
    "    },\n",
    "    'cora_full':{\n",
    "        'desc': \"Question: Which category from the list that the paper most likely belong to?\",\n",
    "        'categories': ['Artificial_Intelligence/Agents/',\n",
    "                        'Artificial_Intelligence/Data_Mining/',\n",
    "                        'Artificial_Intelligence/Expert_Systems/',\n",
    "                        'Artificial_Intelligence/Games_and_Search/',\n",
    "                        'Artificial_Intelligence/Knowledge_Representation/',\n",
    "                        'Artificial_Intelligence/Machine_Learning/Case-Based/',\n",
    "                        'Artificial_Intelligence/Machine_Learning/Genetic_Algorithms/',\n",
    "                        'Artificial_Intelligence/Machine_Learning/Neural_Networks/',\n",
    "                        'Artificial_Intelligence/Machine_Learning/Probabilistic_Methods/',\n",
    "                        'Artificial_Intelligence/Machine_Learning/Reinforcement_Learning/',\n",
    "                        'Artificial_Intelligence/Machine_Learning/Rule_Learning/',\n",
    "                        'Artificial_Intelligence/Machine_Learning/Theory/',\n",
    "                        'Artificial_Intelligence/NLP/',\n",
    "                        'Artificial_Intelligence/Planning/',\n",
    "                        'Artificial_Intelligence/Robotics/',\n",
    "                        'Artificial_Intelligence/Speech/',\n",
    "                        'Artificial_Intelligence/Theorem_Proving/',\n",
    "                        'Artificial_Intelligence/Vision_and_Pattern_Recognition/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Computational_Complexity/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Computational_Geometry/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Formal_Languages/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Hashing/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Logic/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Parallel/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Quantum_Computing/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Randomized/',\n",
    "                        'Data_Structures__Algorithms_and_Theory/Sorting/',\n",
    "                        'Databases/Concurrency/',\n",
    "                        'Databases/Deductive/',\n",
    "                        'Databases/Object_Oriented/',\n",
    "                        'Databases/Performance/',\n",
    "                        'Databases/Query_Evaluation/',\n",
    "                        'Databases/Relational/',\n",
    "                        'Databases/Temporal/',\n",
    "                        'Encryption_and_Compression/Compression/',\n",
    "                        'Encryption_and_Compression/Encryption/',\n",
    "                        'Encryption_and_Compression/Security/',\n",
    "                        'Hardware_and_Architecture/Distributed_Architectures/',\n",
    "                        'Hardware_and_Architecture/High_Performance_Computing/',\n",
    "                        'Hardware_and_Architecture/Input_Output_and_Storage/',\n",
    "                        'Hardware_and_Architecture/Logic_Design/',\n",
    "                        'Hardware_and_Architecture/Memory_Structures/',\n",
    "                        'Hardware_and_Architecture/Microprogramming/',\n",
    "                        'Hardware_and_Architecture/VLSI/',\n",
    "                        'Human_Computer_Interaction/Cooperative/',\n",
    "                        'Human_Computer_Interaction/Graphics_and_Virtual_Reality/',\n",
    "                        'Human_Computer_Interaction/Interface_Design/',\n",
    "                        'Human_Computer_Interaction/Multimedia/',\n",
    "                        'Human_Computer_Interaction/Wearable_Computers/',\n",
    "                        'Information_Retrieval/Digital_Library/',\n",
    "                        'Information_Retrieval/Extraction/',\n",
    "                        'Information_Retrieval/Filtering/',\n",
    "                        'Information_Retrieval/Retrieval/',\n",
    "                        'Networking/Internet/',\n",
    "                        'Networking/Protocols/',\n",
    "                        'Networking/Routing/',\n",
    "                        'Networking/Wireless/',\n",
    "                        'Operating_Systems/Distributed/',\n",
    "                        'Operating_Systems/Fault_Tolerance/',\n",
    "                        'Operating_Systems/Memory_Management/',\n",
    "                        'Operating_Systems/Realtime/',\n",
    "                        'Programming/Compiler_Design/',\n",
    "                        'Programming/Debugging/',\n",
    "                        'Programming/Functional/',\n",
    "                        'Programming/Garbage_Collection/',\n",
    "                        'Programming/Java/',\n",
    "                        'Programming/Logic/',\n",
    "                        'Programming/Object_Oriented/',\n",
    "                        'Programming/Semantics/',\n",
    "                        'Programming/Software_Development/'],\n",
    "        'question': \"Given the title and abstract of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\"\n",
    "    },\n",
    "    'pubmed':{\n",
    "        'desc': \"Question: Which category from the list that the paper most likely belong to?\",\n",
    "        'categories': ['Diabetes Mellitus Type 1', 'Diabetes Mellitus Type 2','Diabetes Mellitus, Experimental'],\n",
    "        'question': \"Given the keywords of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\"\n",
    "    },\n",
    "    'aids':{\n",
    "        'desc': \"Question: Which category from the list that the input molecule most likely belong to?\",\n",
    "        'categories': ['HIV antiviral active compound', 'HIV antiviral inactive compound'],\n",
    "        'question': \"Given the atoms type and their connection structure of a compound, identify if the given compound is HIV antiviral active or not.\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME_PATH = \"/home/ubuntu/proj/data/graph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"{DATA_HOME_PATH}/node_pubmed\"\n",
    "DATA_NAME = \"text_graph_pubmed\" #\"text_graph_aids\" #\"text_graph_pubmed\" # # \"text_graph_cora\"\n",
    "TRAIN_SPLIT_NAME = 'train_index'\n",
    "TEST_SPLIT_NAME = 'test_index'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, f\"{DATA_NAME}.pkl\"), 'rb') as f:\n",
    "    graph = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TRAIN_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    train_split = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TEST_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    test_split = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'prompt_tuning'\n",
    "pubmed_item = Item(\n",
    "    desc = \"Question: Which category from the list that the paper most likely belong to?\",\n",
    "    categories = ['Diabetes Mellitus Type 1', 'Diabetes Mellitus Type 2','Diabetes Mellitus, Experimental'],\n",
    "    question = \"Given the keywords of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\"\n",
    "    )\n",
    "hard_prompt = get_prompt_tuning_prompt(\n",
    "    task_name = task_name,\n",
    "    task_item = pubmed_item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### USER: Question: Which category from the list that the paper most likely belong to? \n",
      "\n",
      "Belows are 3 potential categories to consider:\n",
      "Category [1](Diabetes Mellitus Type 1) \n",
      "Category [2](Diabetes Mellitus Type 2) \n",
      "Category [3](Diabetes Mellitus, Experimental) \n",
      "\n",
      "Given the keywords of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\n",
      "### ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "print(hard_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, test_samples = [], []\n",
    "train_pos_tokens, test_pos_tokens = graph.x[torch.tensor(train_split)], graph.x[torch.tensor(test_split)]\n",
    "train_y_labels, test_y_labels = (np.array(graph.text_node_labels)[np.array(train_split)]).tolist(), (np.array(graph.text_node_labels)[np.array(test_split)]).tolist()\n",
    "for label in train_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    train_samples.append(sample)\n",
    "    \n",
    "for label in test_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    test_samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18717, 1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_tokens = train_pos_tokens.view(-1, 1, 768)\n",
    "test_pos_tokens = test_pos_tokens.view(-1, 1, 768)\n",
    "len(train_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(pos_token_tensor, all_input_examples):\n",
    "    for tensor, example in zip(pos_token_tensor, all_input_examples):\n",
    "        yield {\n",
    "            'prompt_tokens': tensor.numpy(), \n",
    "            'instruction': example['instruction'], \n",
    "            'output': example['output']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/pubmed/train.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in train_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "output_path = '../data/pubmed/test.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in test_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "torch.save(train_pos_tokens, '../data/pubmed/train.pt')\n",
    "torch.save(test_pos_tokens, '../data/pubmed/test.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"{DATA_HOME_PATH}/node_ogb_arxiv\"\n",
    "DATA_NAME = \"text_graph_arxiv\" #\"text_graph_aids\" #\"text_graph_pubmed\" # # \"text_graph_cora\"\n",
    "TRAIN_SPLIT_NAME = 'train_index'\n",
    "VALID_SPLIT_NAME = 'valid_index'\n",
    "TEST_SPLIT_NAME = 'test_index'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, f\"{DATA_NAME}.pkl\"), 'rb') as f:\n",
    "    graph = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TRAIN_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    train_split = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{VALID_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    valid_split = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TEST_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    test_split = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'prompt_tuning'\n",
    "PROMPT_SETTINGS_DICT = PROMPT_SETTINGS['arxiv']\n",
    "desc, categories, question = PROMPT_SETTINGS_DICT['desc'], PROMPT_SETTINGS_DICT['categories'], PROMPT_SETTINGS_DICT['question']\n",
    "input_item = Item(\n",
    "    desc = desc,\n",
    "    categories = categories,\n",
    "    question = question\n",
    "    )\n",
    "hard_prompt = get_prompt_tuning_prompt(\n",
    "    task_name = task_name,\n",
    "    task_item = input_item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### USER: Question: Which category from the list that the paper most likely belong to? \n",
      "\n",
      "Belows are 40 potential categories to consider:\n",
      "Category [1](Artificial Intelligence) \n",
      "Category [2](Computation and Language) \n",
      "Category [3](Computational Complexity) \n",
      "Category [4](Computational Engineering, Finance, and Science) \n",
      "Category [5](Computational Geometry) \n",
      "Category [6](Computer Science and Game Theory) \n",
      "Category [7](Computer Vision and Pattern Recognition) \n",
      "Category [8](Computers and Society) \n",
      "Category [9](Cryptography and Security) \n",
      "Category [10](Data Structures and Algorithms) \n",
      "Category [11](Databases) \n",
      "Category [12](Digital Libraries) \n",
      "Category [13](Discrete Mathematics) \n",
      "Category [14](Distributed, Parallel, and Cluster Computing) \n",
      "Category [15](Emerging Technologies) \n",
      "Category [16](Formal Languages and Automata Theory) \n",
      "Category [17](General Literature) \n",
      "Category [18](Graphics) \n",
      "Category [19](Hardware Architecture) \n",
      "Category [20](Human-Computer Interaction) \n",
      "Category [21](Information Retrieval) \n",
      "Category [22](Information Theory) \n",
      "Category [23](Logic in Computer Science) \n",
      "Category [24](Machine Learning) \n",
      "Category [25](Mathematical Software) \n",
      "Category [26](Multiagent Systems) \n",
      "Category [27](Multimedia) \n",
      "Category [28](Networking and Internet Architecture) \n",
      "Category [29](Neural and Evolutionary Computing) \n",
      "Category [30](Numerical Analysis) \n",
      "Category [31](Operating Systems) \n",
      "Category [32](Other Computer Science) \n",
      "Category [33](Performance) \n",
      "Category [34](Programming Languages) \n",
      "Category [35](Robotics) \n",
      "Category [36](Social and Information Networks) \n",
      "Category [37](Software Engineering) \n",
      "Category [38](Sound) \n",
      "Category [39](Symbolic Computation) \n",
      "Category [40](Systems and Control) \n",
      "\n",
      "Given the title and abstract of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\n",
      "### ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "print(hard_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, valid_samples, test_samples = [], [], []\n",
    "train_pos_tokens, valid_pos_tokens, test_pos_tokens = graph.x[torch.tensor(train_split)], graph.x[torch.tensor(valid_split)], graph.x[torch.tensor(test_split)]\n",
    "train_y_labels, valid_y_labels, test_y_labels = (np.array(graph.text_node_labels)[np.array(train_split)]).tolist(), (np.array(graph.text_node_labels)[np.array(valid_split)]).tolist(), (np.array(graph.text_node_labels)[np.array(test_split)]).tolist()\n",
    "for label in train_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    train_samples.append(sample)\n",
    "    \n",
    "for label in valid_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    valid_samples.append(sample)\n",
    "    \n",
    "for label in test_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    test_samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90941, 29799, 48603)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_tokens = train_pos_tokens.view(-1, 1, 768)\n",
    "valid_pos_tokens = valid_pos_tokens.view(-1, 1, 768)\n",
    "test_pos_tokens = test_pos_tokens.view(-1, 1, 768)\n",
    "len(train_samples), len(valid_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/arxiv/train.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in train_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "output_path = '../data/arxiv/valid.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in valid_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "output_path = '../data/arxiv/test.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in test_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "torch.save(train_pos_tokens, '../data/arxiv/train.pt')\n",
    "torch.save(valid_pos_tokens, '../data/arxiv/valid.pt')\n",
    "torch.save(test_pos_tokens, '../data/arxiv/test.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cora Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"{DATA_HOME_PATH}/node_cora_full\"\n",
    "DATA_NAME = \"text_graph_cora_full\" #\"text_graph_aids\" #\"text_graph_pubmed\" # # \"text_graph_cora\"\n",
    "TRAIN_SPLIT_NAME = 'train_index'\n",
    "VALID_SPLIT_NAME = 'valid_index'\n",
    "TEST_SPLIT_NAME = 'test_index'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, f\"{DATA_NAME}.pkl\"), 'rb') as f:\n",
    "    graph = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TRAIN_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    train_split = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{VALID_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    valid_split = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TEST_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    test_split = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_categories = [item.strip() for item in (np.unique(graph.text_node_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'prompt_tuning'\n",
    "PROMPT_SETTINGS_DICT = PROMPT_SETTINGS['cora_full']\n",
    "desc, categories, question = PROMPT_SETTINGS_DICT['desc'], PROMPT_SETTINGS_DICT['categories'], PROMPT_SETTINGS_DICT['question']\n",
    "input_item = Item(\n",
    "    desc = desc,\n",
    "    categories = categories,\n",
    "    question = question\n",
    "    )\n",
    "hard_prompt = get_prompt_tuning_prompt(\n",
    "    task_name = task_name,\n",
    "    task_item = input_item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### USER: Question: Which category from the list that the paper most likely belong to? \n",
      "\n",
      "Belows are 70 potential categories to consider:\n",
      "Category [1](Artificial_Intelligence/Agents/) \n",
      "Category [2](Artificial_Intelligence/Data_Mining/) \n",
      "Category [3](Artificial_Intelligence/Expert_Systems/) \n",
      "Category [4](Artificial_Intelligence/Games_and_Search/) \n",
      "Category [5](Artificial_Intelligence/Knowledge_Representation/) \n",
      "Category [6](Artificial_Intelligence/Machine_Learning/Case-Based/) \n",
      "Category [7](Artificial_Intelligence/Machine_Learning/Genetic_Algorithms/) \n",
      "Category [8](Artificial_Intelligence/Machine_Learning/Neural_Networks/) \n",
      "Category [9](Artificial_Intelligence/Machine_Learning/Probabilistic_Methods/) \n",
      "Category [10](Artificial_Intelligence/Machine_Learning/Reinforcement_Learning/) \n",
      "Category [11](Artificial_Intelligence/Machine_Learning/Rule_Learning/) \n",
      "Category [12](Artificial_Intelligence/Machine_Learning/Theory/) \n",
      "Category [13](Artificial_Intelligence/NLP/) \n",
      "Category [14](Artificial_Intelligence/Planning/) \n",
      "Category [15](Artificial_Intelligence/Robotics/) \n",
      "Category [16](Artificial_Intelligence/Speech/) \n",
      "Category [17](Artificial_Intelligence/Theorem_Proving/) \n",
      "Category [18](Artificial_Intelligence/Vision_and_Pattern_Recognition/) \n",
      "Category [19](Data_Structures__Algorithms_and_Theory/Computational_Complexity/) \n",
      "Category [20](Data_Structures__Algorithms_and_Theory/Computational_Geometry/) \n",
      "Category [21](Data_Structures__Algorithms_and_Theory/Formal_Languages/) \n",
      "Category [22](Data_Structures__Algorithms_and_Theory/Hashing/) \n",
      "Category [23](Data_Structures__Algorithms_and_Theory/Logic/) \n",
      "Category [24](Data_Structures__Algorithms_and_Theory/Parallel/) \n",
      "Category [25](Data_Structures__Algorithms_and_Theory/Quantum_Computing/) \n",
      "Category [26](Data_Structures__Algorithms_and_Theory/Randomized/) \n",
      "Category [27](Data_Structures__Algorithms_and_Theory/Sorting/) \n",
      "Category [28](Databases/Concurrency/) \n",
      "Category [29](Databases/Deductive/) \n",
      "Category [30](Databases/Object_Oriented/) \n",
      "Category [31](Databases/Performance/) \n",
      "Category [32](Databases/Query_Evaluation/) \n",
      "Category [33](Databases/Relational/) \n",
      "Category [34](Databases/Temporal/) \n",
      "Category [35](Encryption_and_Compression/Compression/) \n",
      "Category [36](Encryption_and_Compression/Encryption/) \n",
      "Category [37](Encryption_and_Compression/Security/) \n",
      "Category [38](Hardware_and_Architecture/Distributed_Architectures/) \n",
      "Category [39](Hardware_and_Architecture/High_Performance_Computing/) \n",
      "Category [40](Hardware_and_Architecture/Input_Output_and_Storage/) \n",
      "Category [41](Hardware_and_Architecture/Logic_Design/) \n",
      "Category [42](Hardware_and_Architecture/Memory_Structures/) \n",
      "Category [43](Hardware_and_Architecture/Microprogramming/) \n",
      "Category [44](Hardware_and_Architecture/VLSI/) \n",
      "Category [45](Human_Computer_Interaction/Cooperative/) \n",
      "Category [46](Human_Computer_Interaction/Graphics_and_Virtual_Reality/) \n",
      "Category [47](Human_Computer_Interaction/Interface_Design/) \n",
      "Category [48](Human_Computer_Interaction/Multimedia/) \n",
      "Category [49](Human_Computer_Interaction/Wearable_Computers/) \n",
      "Category [50](Information_Retrieval/Digital_Library/) \n",
      "Category [51](Information_Retrieval/Extraction/) \n",
      "Category [52](Information_Retrieval/Filtering/) \n",
      "Category [53](Information_Retrieval/Retrieval/) \n",
      "Category [54](Networking/Internet/) \n",
      "Category [55](Networking/Protocols/) \n",
      "Category [56](Networking/Routing/) \n",
      "Category [57](Networking/Wireless/) \n",
      "Category [58](Operating_Systems/Distributed/) \n",
      "Category [59](Operating_Systems/Fault_Tolerance/) \n",
      "Category [60](Operating_Systems/Memory_Management/) \n",
      "Category [61](Operating_Systems/Realtime/) \n",
      "Category [62](Programming/Compiler_Design/) \n",
      "Category [63](Programming/Debugging/) \n",
      "Category [64](Programming/Functional/) \n",
      "Category [65](Programming/Garbage_Collection/) \n",
      "Category [66](Programming/Java/) \n",
      "Category [67](Programming/Logic/) \n",
      "Category [68](Programming/Object_Oriented/) \n",
      "Category [69](Programming/Semantics/) \n",
      "Category [70](Programming/Software_Development/) \n",
      "\n",
      "Given the title and abstract of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\n",
      "### ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "print(hard_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4161"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, valid_samples, test_samples = [], [], []\n",
    "train_pos_tokens, valid_pos_tokens, test_pos_tokens = graph.x[torch.tensor(train_split)], graph.x[torch.tensor(valid_split)], graph.x[torch.tensor(test_split)]\n",
    "train_y_labels, valid_y_labels, test_y_labels = (np.array(graph.text_node_labels)[np.array(train_split)]).tolist(), (np.array(graph.text_node_labels)[np.array(valid_split)]).tolist(), (np.array(graph.text_node_labels)[np.array(test_split)]).tolist()\n",
    "for label in train_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    train_samples.append(sample)\n",
    "    \n",
    "for label in valid_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    valid_samples.append(sample)\n",
    "    \n",
    "for label in test_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    test_samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 1400, 22704)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_tokens = train_pos_tokens.view(-1, 1, 768)\n",
    "valid_pos_tokens = valid_pos_tokens.view(-1, 1, 768)\n",
    "test_pos_tokens = test_pos_tokens.view(-1, 1, 768)\n",
    "len(train_samples), len(valid_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/cora_full/train.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in train_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "\n",
    "output_path = '../data/cora_full/valid.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in valid_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "\n",
    "output_path = '../data/cora_full/test.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in test_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "\n",
    "torch.save(train_pos_tokens, '../data/cora_full/train.pt')\n",
    "torch.save(valid_pos_tokens, '../data/cora_full/valid.pt')\n",
    "torch.save(test_pos_tokens, '../data/cora_full/test.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([700, 1, 768]),\n",
       " torch.Size([1400, 1, 768]),\n",
       " torch.Size([22704, 1, 768]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_tokens.shape, valid_pos_tokens.shape, test_pos_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 1400, 22704)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_split)), len(np.unique(valid_split)), len(np.unique(test_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = f\"{DATA_HOME_PATH}/node_cora\"\n",
    "DATA_NAME = \"text_graph_cora\" #\"text_graph_aids\" #\"text_graph_pubmed\" # # \"text_graph_cora\"\n",
    "TRAIN_SPLIT_NAME = 'train_index'\n",
    "VALID_SPLIT_NAME = 'valid_index'\n",
    "TEST_SPLIT_NAME = 'test_index'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, f\"{DATA_NAME}.pkl\"), 'rb') as f:\n",
    "    graph = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TRAIN_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    train_split = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{VALID_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    valid_split = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TEST_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    test_split = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_categories = [item.strip() for item in (np.unique(graph.text_node_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'prompt_tuning'\n",
    "PROMPT_SETTINGS_DICT = PROMPT_SETTINGS['cora']\n",
    "desc, categories, question = PROMPT_SETTINGS_DICT['desc'], PROMPT_SETTINGS_DICT['categories'], PROMPT_SETTINGS_DICT['question']\n",
    "input_item = Item(\n",
    "    desc = desc,\n",
    "    categories = categories,\n",
    "    question = question\n",
    "    )\n",
    "hard_prompt = get_prompt_tuning_prompt(\n",
    "    task_name = task_name,\n",
    "    task_item = input_item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### USER: Question: Which category from the list that the paper most likely belong to? \n",
      "\n",
      "Belows are 7 potential categories to consider:\n",
      "Category [1](Case-Based) \n",
      "Category [2](Genetic_Algorithms) \n",
      "Category [3](Neural_Networks) \n",
      "Category [4](Probabilistic_Methods) \n",
      "Category [5](Reinforcement_Learning) \n",
      "Category [6](Rule_Learning) \n",
      "Category [7](Theory) \n",
      "\n",
      "Given the title and abstract of a research paper, identify one category from a distinct list of research topics that you predict the paper will most likely belong to.\n",
      "### ASSISTANT:\n"
     ]
    }
   ],
   "source": [
    "print(hard_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, valid_samples, test_samples = [], [], []\n",
    "train_pos_tokens, valid_pos_tokens, test_pos_tokens = graph.x[torch.tensor(train_split)], graph.x[torch.tensor(valid_split)], graph.x[torch.tensor(test_split)]\n",
    "train_y_labels, valid_y_labels, test_y_labels = (np.array(graph.text_node_labels)[np.array(train_split)]).tolist(), (np.array(graph.text_node_labels)[np.array(valid_split)]).tolist(), (np.array(graph.text_node_labels)[np.array(test_split)]).tolist()\n",
    "for label in train_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    train_samples.append(sample)\n",
    "    \n",
    "for label in valid_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    valid_samples.append(sample)\n",
    "    \n",
    "for label in test_y_labels:\n",
    "    formated_ans = f\"This paper most likely belong to {label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    test_samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1624, 542, 542)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples), len(valid_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/cora/train.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in train_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "\n",
    "output_path = '../data/cora/valid.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in valid_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "\n",
    "output_path = '../data/cora/test.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in test_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ec2-user/proj/datasets/graph/text_graph\"\n",
    "DATA_NAME = \"text_graph_aids\" #\"text_graph_aids\" #\"text_graph_pubmed\" # # \"text_graph_cora\"\n",
    "TRAIN_SPLIT_NAME = 'train_index'\n",
    "TEST_SPLIT_NAME = 'test_index'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, f\"{DATA_NAME}.pkl\"), 'rb') as f:\n",
    "    graph = pkl.load(f)\n",
    "train_split = list(np.random.choice(np.arange(len(graph)), 1600, replace=False))\n",
    "test_split = []\n",
    "for i in range(len(graph)):\n",
    "    if i not in train_split:\n",
    "        test_split.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'prompt_tuning'\n",
    "PROMPT_SETTINGS_DICT = PROMPT_SETTINGS['aids']\n",
    "desc, categories, question = PROMPT_SETTINGS_DICT['desc'], PROMPT_SETTINGS_DICT['categories'], PROMPT_SETTINGS_DICT['question']\n",
    "input_item = Item(\n",
    "    desc = desc,\n",
    "    categories = categories,\n",
    "    question = question\n",
    "    )\n",
    "hard_prompt = get_prompt_tuning_prompt(\n",
    "    task_name = task_name,\n",
    "    task_item = input_item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which category from the list that the input molecule most likely belong to? \n",
      "\n",
      "Belows are 2 potential categories to consider:\n",
      "Category [1](HIV antiviral active compound) \n",
      "Category [2](HIV antiviral inactive compound) \n",
      "\n",
      "Given the atoms type and their connection structure of a compound, identify if the given compound is HIV antiviral active or not.\n"
     ]
    }
   ],
   "source": [
    "print(hard_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 32639.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train_samples, test_samples = [], []\n",
    "X = torch.stack([graph[i].x.mean(dim=0) for i in range(len(graph))])\n",
    "train_pos_tokens, test_pos_tokens = X[torch.tensor(train_split)], X[torch.tensor(test_split)]\n",
    "for i in tqdm(range(len(graph))):\n",
    "    formated_ans = f\"This compound most likely belong to {graph[i].text_graph_label}\"\n",
    "    sample = {\n",
    "        'instruction': hard_prompt,\n",
    "        'output': formated_ans,\n",
    "    }\n",
    "    if i in train_split:\n",
    "        train_samples.append(sample)\n",
    "    elif i in test_split:\n",
    "        test_samples.append(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 400)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_tokens = train_pos_tokens.view(-1, 1, 768)\n",
    "test_pos_tokens = test_pos_tokens.view(-1, 1, 768)\n",
    "len(train_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../data/aids/train.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in train_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "output_path = '../data/aids/test.jsonl'\n",
    "with xopen(output_path, \"w\") as f:\n",
    "    for output_example in test_samples:\n",
    "        f.write(json.dumps(output_example) + \"\\n\")\n",
    "torch.save(train_pos_tokens, '../data/aids/train.pt')\n",
    "torch.save(test_pos_tokens, '../data/aids/test.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/ubuntu/data/graph/edge_ogbl_wiki\"\n",
    "DATA_NAME = \"text_graph_wiki\" #\"text_graph_aids\" #\"text_graph_pubmed\" # # \"text_graph_cora\"\n",
    "TRAIN_SPLIT_NAME = 'train_index'\n",
    "TEST_SPLIT_NAME = 'test_index'\n",
    "\n",
    "with open(os.path.join(DATA_PATH, f\"{DATA_NAME}.pkl\"), 'rb') as f:\n",
    "    graph = pkl.load(f)\n",
    "with open(os.path.join(DATA_PATH, f\"{TRAIN_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    train_split = pkl.load(f)\n",
    "    train_split = list(np.unique(train_split))\n",
    "with open(os.path.join(DATA_PATH, f\"{TEST_SPLIT_NAME}.pkl\"), 'rb') as f:\n",
    "    test_split = pkl.load(f)\n",
    "    test_split = list(np.unique(test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(text_nodes=[46210], text_node_labels=[46210], text_graph_label='None', text_edge_labels=[34273], x=[46210, 768], y=[46210], edge_index=[2, 34273])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229.66"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "66.64+60+1.64+44.66+56.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zheng_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
