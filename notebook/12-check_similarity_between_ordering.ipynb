{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/graphllm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "from xopen import xopen\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "def simMatrix(A: torch.tensor, B: torch.tensor) -> torch.tensor:\n",
    "    # Assume A and B are your input tensors of shape (N, d)\n",
    "    # Example: A = torch.randn(N, d)\n",
    "    #          B = torch.randn(N, d)\n",
    "\n",
    "    # Step 1: Normalize A and B\n",
    "    A_norm = A / A.norm(dim=1, keepdim=True)\n",
    "    B_norm = B / B.norm(dim=1, keepdim=True)\n",
    "\n",
    "    # Step 2: Compute the dot product\n",
    "    cosine_similarity_matrix = torch.mm(A_norm, B_norm.transpose(0, 1))\n",
    "\n",
    "    # The resulting cosine_similarity_matrix is of shape (N, N)\n",
    "    # and contains values in the range [-1, 1]\n",
    "    return cosine_similarity_matrix\n",
    "\n",
    "DATA_PATH = \"/home/ubuntu/proj/data/graph/node_pubmed\"\n",
    "DATA_NAME = \"text_graph_pubmed\" # \"text_graph_pubmed\" #\"text_graph_aids\" #\"text_graph_pubmed\" # # \n",
    "\n",
    "with open(os.path.join(DATA_PATH, f\"{DATA_NAME}.pkl\"), 'rb') as f:\n",
    "    graph = pkl.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_levels_embedding = dict()\n",
    "for relevance_type in ['pos','neg','random_1','random_2','random_3']:\n",
    "    all_levels_embedding[relevance_type] = dict()\n",
    "    # build 0-order textual-graph\n",
    "    text_nodes = graph.text_nodes\n",
    "    edge_index = graph.edge_index\n",
    "    k = 2\n",
    " \n",
    "    for order in range(0, k+1):\n",
    "        all_levels_embedding[relevance_type][order] = torch.load(os.path.join(DATA_PATH, relevance_type, f\"order-{order}-bert.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=0, relevance_type_1='pos', relevance_type_2='neg', 1.0000\n",
      "k=1, relevance_type_1='pos', relevance_type_2='neg', 0.9997\n",
      "k=2, relevance_type_1='pos', relevance_type_2='neg', 0.9998\n",
      "k=0, relevance_type_1='pos', relevance_type_2='random_1', 1.0000\n",
      "k=1, relevance_type_1='pos', relevance_type_2='random_1', 0.9987\n",
      "k=2, relevance_type_1='pos', relevance_type_2='random_1', 0.9970\n",
      "k=0, relevance_type_1='pos', relevance_type_2='random_2', 1.0000\n",
      "k=1, relevance_type_1='pos', relevance_type_2='random_2', 0.9987\n",
      "k=2, relevance_type_1='pos', relevance_type_2='random_2', 0.9970\n",
      "k=0, relevance_type_1='pos', relevance_type_2='random_3', 1.0000\n",
      "k=1, relevance_type_1='pos', relevance_type_2='random_3', 0.9987\n",
      "k=2, relevance_type_1='pos', relevance_type_2='random_3', 0.9970\n",
      "k=0, relevance_type_1='neg', relevance_type_2='random_1', 1.0000\n",
      "k=1, relevance_type_1='neg', relevance_type_2='random_1', 0.9987\n",
      "k=2, relevance_type_1='neg', relevance_type_2='random_1', 0.9970\n",
      "k=0, relevance_type_1='neg', relevance_type_2='random_2', 1.0000\n",
      "k=1, relevance_type_1='neg', relevance_type_2='random_2', 0.9987\n",
      "k=2, relevance_type_1='neg', relevance_type_2='random_2', 0.9970\n",
      "k=0, relevance_type_1='neg', relevance_type_2='random_3', 1.0000\n",
      "k=1, relevance_type_1='neg', relevance_type_2='random_3', 0.9987\n",
      "k=2, relevance_type_1='neg', relevance_type_2='random_3', 0.9970\n",
      "k=0, relevance_type_1='random_1', relevance_type_2='random_2', 1.0000\n",
      "k=1, relevance_type_1='random_1', relevance_type_2='random_2', 0.9998\n",
      "k=2, relevance_type_1='random_1', relevance_type_2='random_2', 0.9999\n",
      "k=0, relevance_type_1='random_1', relevance_type_2='random_3', 1.0000\n",
      "k=1, relevance_type_1='random_1', relevance_type_2='random_3', 0.9998\n",
      "k=2, relevance_type_1='random_1', relevance_type_2='random_3', 0.9999\n",
      "k=0, relevance_type_1='random_2', relevance_type_2='random_3', 1.0000\n",
      "k=1, relevance_type_1='random_2', relevance_type_2='random_3', 0.9998\n",
      "k=2, relevance_type_1='random_2', relevance_type_2='random_3', 0.9999\n"
     ]
    }
   ],
   "source": [
    "types_choice = ['pos','neg','random_1','random_2','random_3']\n",
    "for i in range(len(types_choice)):\n",
    "    for j in range(i+1,len(types_choice)):\n",
    "        relevance_type_1 = types_choice[i]\n",
    "        relevance_type_2 = types_choice[j]\n",
    "        for k in range(3):\n",
    "            cosine_values = simMatrix(\n",
    "                all_levels_embedding[relevance_type_1][k].squeeze(-2),\n",
    "                all_levels_embedding[relevance_type_2][k].squeeze(-2)\n",
    "            ).diag().numpy()\n",
    "            average_value = np.mean(cosine_values)\n",
    "            std_value = np.std(cosine_values)\n",
    "            print(f\"{k=}, {relevance_type_1=}, {relevance_type_2=}, {average_value:.4f}\".format(average_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9493)\n",
      "tensor(0.9241)\n",
      "tensor(0.9285)\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "    print(simMatrix(\n",
    "                    all_levels_embedding['neg'][k].squeeze(-2),\n",
    "                    all_levels_embedding['neg'][k].squeeze(-2)\n",
    "                ).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
